{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd00006681b65552ee06a06484d6e979b18764f8243836b7c1a62fbc4ac5eee8365",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Hello  and welcome to Jon Dexter's ML class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main libraries we using in the project\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split        #for spliting our data into train & test\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # this lib actually\n",
    "#converts data in text or images format to numerical formats for machine learnigng algorithms to be able to use\n",
    "from sklearn import svm                                     #our classification lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our general classes\n",
    "\n",
    "class Sentiments:\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    POSITIVE = 'POSITIVE'\n",
    "    NUETRAL = 'NEUTRAL'\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiments.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiments.NUETRAL\n",
    "        else:\n",
    "            return Sentiments.POSITIVE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and store in a list... \n",
    "#note the list contains both the reviewText and its correspondind score, defined as the overall\n",
    "reviews = []\n",
    "\n",
    "with open('amazon_books_review_data_10000.json') as review_data:\n",
    "    for line in review_data:\n",
    "        line = json.loads(line)   ##########\n",
    "        reviews.append(Review(line['reviewText'], line['overall']))   #adding to the list now...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just trying to put the data unto a df\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['Text'] = [x.text for x in reviews]\n",
    "data['Score'] = [x.score for x in reviews]\n",
    "data['Sentiments'] = [x.get_sentiment() for x in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now split the data into train and test datasets \n",
    "#text is inputs, ie X and sentiments for output, ie Y\n",
    "\n",
    "train, test = train_test_split(reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = [x.text for x in train]\n",
    "train_output = [x.sentiment for x in train]\n",
    "\n",
    "test_input = [y.text for y in test]\n",
    "test_output = [y.sentiment for y in test]"
   ]
  },
  {
   "source": [
    "Vecortize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we vectorise the training data.... note the trainning data is a text data, ml models wont be able to work on them well, so we have to find a way of converting them into numerical data... thats what we call the vectorization... find more info online for more clarification\n",
    "\n",
    "vectorizer = CountVectorizer()    #instance of the method\n",
    "\n",
    "vectorizer.fit(train_input)\n",
    "train_input_vectors = vectorizer.transform(train_input)\n",
    "#this two methods are standards, first you fit and then you transform\n",
    "\n",
    "#now we have the actual data we will be using for the training ie...\n",
    "#train_input_vectors\n",
    "#train_output\n",
    "\n",
    "#we need to also vectorize our input test datasets\n",
    "test_input_vectors = vectorizer.transform(test_input)"
   ]
  },
  {
   "source": [
    "SVM Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#now we do some classification of the data\n",
    "#there are several libraries for this but we going for SVC..... alert(l'll do a research to outline the various classification models available and thier pros and cons with some good recommendations )\n",
    "\n",
    "svm_clf = svm.SVC(kernel='linear')                      #this is a linear classification\n",
    "\n",
    "svm_clf.fit(train_input_vectors, train_output)          #pass the training input and output datasets\n",
    "\n",
    "#then we try predicting something\n",
    "svm_clf.predict(test_input_vectors[0])\n",
    "\n",
    "#then we check the accuracy using this model\n"
   ]
  },
  {
   "source": [
    "Decision tree"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc_clf = DecisionTreeClassifier()\n",
    "dtc_clf.fit(train_input_vectors, train_output)\n",
    "\n",
    "#predictiing somethins\n",
    "dtc_clf.predict(test_input_vectors[0])"
   ]
  },
  {
   "source": [
    "Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(train_input_vectors.toarray(), train_output)\n",
    "\n",
    "#predicting\n",
    "gnb_clf.predict(test_input_vectors[0].toarray())"
   ]
  },
  {
   "source": [
    "Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/jondexter/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_input_vectors, train_output)\n",
    "\n",
    "#now we predict\n",
    "lr_clf.predict(test_input_vectors[0])"
   ]
  },
  {
   "source": [
    "Evaluations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8124242424242424\n",
      "0.7678787878787878\n",
      "0.6587878787878788\n",
      "0.8409090909090909\n"
     ]
    }
   ],
   "source": [
    "#Mean accuracy scores of all classification models used above\n",
    "\n",
    "print(svm_clf.score(test_input_vectors, test_output))               #for SVM\n",
    "print(dtc_clf.score(test_input_vectors, test_output))               #for Decison Tree\n",
    "print(gnb_clf.score(test_input_vectors.toarray(), test_output))     #for Gausssian naive bayes\n",
    "print(lr_clf.score(test_input_vectors, test_output))                #for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.90738061, 0.40268456, 0.2656    ])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#F1 scores\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test_output, svm_clf.predict(test_input_vectors), average=None, labels=[Sentiments.POSITIVE, Sentiments.NEGATIVE, Sentiments.NUETRAL])\n",
    "\n",
    "#this computes the F1 score on all three unique sentiments in our output dataset ie the sentiment column\n",
    "#however, the looking at the result, array([0.91319444, 0.22222222, 0.21052632])\n",
    "#we realise that the predictions is skewed towards the positive sentiments,its highly likely to predict positive sentiment to the rest, the rest must also have a high f1 score not, not o.2 ...."
   ]
  },
  {
   "source": [
    "So here's the fix... we need a larger dataset and we have to make sure the positive sentiments are at the same size as the negative.... just run a quick count and you seee the dataset has more positive sentiments than negative sentiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets do the magic\n",
    "#lets have another class called ReviewContainer\n",
    "\n",
    "import random\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "\n",
    "    def DistributeEvenly(self):\n",
    "        #our code below filters out the various sentiments and tries to evn them out\n",
    "        negative = list(filter(lambda x: x.sentiment==Sentiments.NEGATIVE, reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment==Sentiments.POSITIVE, reviews))\n",
    "        neutral  = list(filter(lambda x: x.sentiment==Sentiments.NUETRAL,  reviews))\n",
    "\n",
    "        #we shrink the rest to the same size as the negative sentiments\n",
    "        positive_shrink = positive[:len(negative)]\n",
    "        neutral_shrink = neutral[:len(negative)]\n",
    "        self.reviews = negative + positive_shrink + neutral_shrink\n",
    "\n",
    "        random.shuffle(self.reviews)\n",
    "\n",
    "        #print(len(positive_shrink))\n",
    "        #print(len(negative))\n",
    "        #print(len(neutral_shrink))\n",
    "        #print(len(self.reviews))\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we take it on from the after we done with the spliting of the data\n",
    "train_v2 = ReviewContainer(train)\n",
    "test_v2 = ReviewContainer(test)\n",
    "train_v2.DistributeEvenly()\n",
    "train_v2_inputs = train_v2.get_text()\n",
    "train_v2_outputs = train_v2.get_sentiment()\n",
    "\n",
    "test_v2_inputs = test_v2.get_text()\n",
    "test_v2_outputs = test_v2.get_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "644\n644\n644\n"
     ]
    }
   ],
   "source": [
    "print(train_v2_outputs.count(Sentiments.NEGATIVE))\n",
    "print(train_v2_outputs.count(Sentiments.POSITIVE))\n",
    "print(train_v2_outputs.count(Sentiments.NUETRAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that they are all of the same size, we can now vectorize and continue\n",
    "vectorizer = CountVectorizer()    #instance of the method\n",
    "\n",
    "vectorizer.fit(train_v2_inputs)\n",
    "train_v2_inputs_vectors = vectorizer.transform(train_v2_inputs)\n",
    "\n",
    "#now we have the actual data we will be using for the training ie...\n",
    "#train_input_vectors\n",
    "#train_output\n",
    "\n",
    "#we need to also vectorize our input test datasets\n",
    "test_v2_inputs_vectors = vectorizer.transform(test_v2_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "#and now the svm model\n",
    "svm_clf = svm.SVC(kernel='linear')                      #this is a linear classification\n",
    "\n",
    "svm_clf.fit(train_v2_inputs_vectors, train_v2_outputs)          #pass the training input and output datasets\n",
    "\n",
    "#then we try predicting something\n",
    "svm_clf.predict(test_v2_inputs_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.78659996, 0.4820394 , 0.4877193 ])"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "f1_score(test_v2_outputs, svm_clf.predict(test_v2_inputs_vectors), average=None, labels=[Sentiments.POSITIVE, Sentiments.NEGATIVE, Sentiments.NUETRAL])\n",
    "#well, it has increased small |(-^_^-)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE', 'NEUTRAL', 'POSITIVE'],\n",
       "      dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "# and now some ramdom test \n",
    "\n",
    "test_data = ['I thorougly enjoyed this book, 5 star', \n",
    "            'Not bad', \n",
    "            'horrible waste of time', \n",
    "            'its a good book but do not buy okay', \n",
    "            'i will recommend it to no one']\n",
    "transformed_test_data = vectorizer.transform(test_data)\n",
    "svm_clf.predict(transformed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}